{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "heading_collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "import os\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import community as community_louvain\n",
    "from IPython.core.display import display, HTML\n",
    "from time import time\n",
    "\n",
    "from import_and_scrape import get_exported_youtube_playlist_ids, scrape, id_to_url\n",
    "\n",
    "# import matplotlib.cm as cm\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "heading_collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# temporary autocompletion bug fix\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_path = \"../data/graph.pickle\"\n",
    "\n",
    "\n",
    "def save_graph(G):\n",
    "    assert 0 == len(list(nx.selfloop_edges(G)))\n",
    "    # selfloop edges shouldn't happen\n",
    "    # G.remove_edges_from(nx.selfloop_edges(G))\n",
    "\n",
    "    with open(graph_path, \"wb\") as handle:\n",
    "        pickle.dump(G, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "def load_graph():\n",
    "    # load or create a Graph\n",
    "    if os.path.isfile(graph_path):\n",
    "        print(\"graph loaded\")\n",
    "        with open(graph_path, \"rb\") as handle:\n",
    "            return pickle.load(handle)\n",
    "    else:\n",
    "        print(\"graph created\")\n",
    "        return nx.DiGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "heading_collapsed": "false"
   },
   "outputs": [],
   "source": [
    "G = load_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "heading_collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# ids_to_add = get_freetube_favorites_ids()\n",
    "ids_to_add, times_liked = get_exported_youtube_playlist_ids(\n",
    "    \"../data/youtube-export/playlists/Liked videos.csv\"\n",
    ")\n",
    "\n",
    "print(f\"adding {len(ids_to_add)} nodes\")\n",
    "\n",
    "for id_, time_liked in zip(ids_to_add, times_liked):\n",
    "    print(\">\", end=\"\")\n",
    "\n",
    "    #     if id_ in G.nodes and \"time_scraped\" in G.nodes[id_]:\n",
    "    #         # this video was already scraped\n",
    "    #         continue\n",
    "\n",
    "    scrape(id_, G)\n",
    "    if id_ in G:\n",
    "        G.nodes[id_][\"time_liked\"] = time_liked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_graph(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "heading_collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def get_liked_from_time_range(G, start, end=None):\n",
    "    if end is None:\n",
    "        end = time()\n",
    "    return [\n",
    "        id_\n",
    "        for id_, node in G.nodes.data()\n",
    "        if \"time_liked\" in node and start < node[\"time_liked\"] < end\n",
    "    ]\n",
    "\n",
    "\n",
    "def sort_nodes_by_in_degree(G, nodes):\n",
    "    recs = sorted(G.subgraph(nodes).in_degree(), key=lambda pair: pair[1], reverse=True)\n",
    "    ids, scores = zip(*recs)\n",
    "    return ids, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "heading_collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# def recommend(SubG, pickiness=0):\n",
    "#     # this line recommends very normie videos\n",
    "#     # it's equivalent to pickiness==0\n",
    "#     # recs = sorted(SubG.in_degree(), key=lambda pair: pair[1], reverse=True)\n",
    "\n",
    "#     # to be honest, I don't fully understand this part\n",
    "#     # but it works better than the one on top:\n",
    "#     # first limit recs only to the best ones\n",
    "#     # this way, we'll omit most general normie recommendations later\n",
    "#     best_recs = [node for node, in_degree in SubG.in_degree() if in_degree >= pickiness]\n",
    "#     #     best_recs = [node for node, degree in SubG.degree() if degree >= pickiness]\n",
    "\n",
    "#     ids, scores = sort_nodes_by_in_degree(SubG, best_recs)\n",
    "#     return ids, scores\n",
    "\n",
    "\n",
    "def display_video_links(G, ids, prefixes=None, show_first=15):\n",
    "    if prefixes is None:\n",
    "        prefixes = [\"\"] * len(ids)\n",
    "\n",
    "    for id_, prefix in list(zip(ids, prefixes))[:show_first]:\n",
    "        if \"title\" not in G.nodes[id_] or G.nodes[id_][\"title\"] is None:\n",
    "            scrape(id_, G)\n",
    "\n",
    "        url = id_to_url.format(id_)\n",
    "        title = G.nodes[id_][\"title\"]\n",
    "        display(HTML(f\"\"\"<a href=\"{url}\">{prefix} {title}</a>\"\"\"))\n",
    "\n",
    "\n",
    "#     save_graph(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seconds_in_year = 60 * 60 * 24 * 365\n",
    "start_time = time() - seconds_in_year * 4\n",
    "sources = get_liked_from_time_range(G, start_time)\n",
    "print(len(sources))\n",
    "# for id_ in sources:\n",
    "#     print(G.nodes[id_][\"title\"])\n",
    "\n",
    "RecentDirected = G.edge_subgraph(G.out_edges(sources))\n",
    "Recent = RecentDirected.to_undirected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # prune\n",
    "\n",
    "# old_nodes_num = -1\n",
    "\n",
    "# while old_nodes_num != len(Recent.nodes):\n",
    "#     old_nodes_num = len(Recent.nodes)\n",
    "#     print(old_nodes_num)\n",
    "#     pruned_nodes = [node for node, degree in Recent.degree() if degree >= 2]\n",
    "#     Recent = Recent.subgraph(pruned_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dendrogram = community_louvain.generate_dendrogram(Recent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition = community_louvain.partition_at_level(dendrogram, 2)\n",
    "\n",
    "cluster_numbers = set(partition.values())\n",
    "len(cluster_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = [node for node, label in partition.items() if label == 11]\n",
    "\n",
    "ids, scores = sort_nodes_by_in_degree(G, cluster)\n",
    "display_video_links(G, ids, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Induced = community_louvain.induced_graph(partition, Recent)\n",
    "Induced.remove_edges_from(nx.selfloop_edges(Induced))\n",
    "# pos = nx.spring_layout(Induced, k=1)\n",
    "# nx.draw(Induced, pos=pos, node_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salient_edges = []\n",
    "for u, v, attributes in Induced.edges.data():\n",
    "    if attributes[\"weight\"] >= 5:\n",
    "        salient_edges.append((u, v))\n",
    "\n",
    "nx.draw(nx.Graph(salient_edges), node_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "heading_collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "heading_collapsed": "false"
   },
   "outputs": [],
   "source": [
    "best_recs = [node for node, in_degree in G.in_degree() if in_degree >= 12]\n",
    "nx.draw(G.subgraph(best_recs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "heading_collapsed": "false",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for n in list(components[0]):\n",
    "    print(nx.algorithms.distance_measures.eccentricity(S.to_undirected(), v=n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "heading_collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
